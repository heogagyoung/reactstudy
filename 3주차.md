advances in attention network



복잡한 이미지에서 윌리를 어떻게 찾을것인가 이미지를 어떻게 찾을것인가.
효율적으로 사용하기위해서 필욯한것



Attention
머신러닝에서 2가지 접근법
soft, hard
이미지를 묘사할때 
어떻게 계산적 효율성을 담당하는가?

1.attention networks as probabilistic models
2.self attention and transformer networks
3.case study : visual question answering

확률분포?
V,Q 는 value 와 query  q와 c question,convaier
k는 필터의 개수
14 by 14가 공간정보를 담고있는 그리드????

conditional probability distribution
joint probability distribution
conditional joint probability distribution

softmax for probability distribution
소프트 맥스 함수는 인풋과 아웃풋????
모든 element는 확률분포에 가져야할 것들을 ?

geometrical interpretation of convex combination

dot product for logits
그래서 이게 뭔데



low rank bilinear pooling for logits
아 좀 공식좀  머리깨ㅐ지것네

쿼리벡터가 주어졌을때 value에 해당하는 부분에서 확률분포를 어떻게 구할것인가?

soft max-> dotproduct 미스매칭할때 임베딩할때 low rank bilinear 모델로 한걸로 같다고?

estimation conditioonal probability

estimation joint probability distibution
P(V,qj) = softmax (Vqj)P((qj)))

대부분을 소프트 맥스 함수에 따라 적는거고 marginal probability distribute????
V는 N by q  Q는 v by N이라고할때 단위매트릭스 곱은 Tby??

dot product
P(V,Q)
Embedding
P(V,Q)
LOW-rank bilinear pooling for jpd

conditional joint probability distribution

handling multiple variables
low rank trilinear pooling
for efficient tensor operation ,,use broadcasting or einsum

einsum in ban
브로드 캐스팅은 더미 차원에 대해 repeat 오퍼레이션을 실행한다..
어떤 알파벳을 쓰는지 안중요함 일관된게 중요함
어떻게 계산을 할 것인가
차원에 대해서 각각 라벨링 

summary 
뭔소린지 1도 모르겠음



----

visual AI의 주요과제

넓고 얉게 

VOS (Video object segmentation)

object detction in the aerial images

video action classification

요즘 비젼문제는 이미지를 많이 다루는데 Video의 중요 테스크
최근 어떻게 연구가 진행되고 있는지 

VOS는 Video에서 object 를 segmentation 하는것이다..
목표가 2가지로 되어있는 semi supervised -one shot
unsupervised (zero shot) 
사람이 지정해주는게 one shot
아닌게 zero shot
유저가 지정한것이냐 아닌것이냐

evaluatiion metric은
얼마나 많이 겹치는지?

region similarity
M : estimated mask
G: GT mask
J = M and G / M or G

contour accuracy

F = 2PcRc / Pc+Rc
P_{c} : precision of contour matching
R_{c} : recall of contour matching
bipartite graph matching is used

 recent trends in vos

온라인 러닝
원샷에 대응하는 테크닉
base net work  ->parent network ->Test Network
어떠한 영상이 주어졌을때 하나의 이미지를 가지고 

online leaning

첫번째 장에서 뽑았다가 나중에 다른 물체를 추적하는 경우가 있다.
그럼에도 불구하고 잘 학습한다.
temporal consistencies를 어떻게 이용할 것인가.

mask propagation
이전 프레임에서 뽑은 프레임 정보를 다음 프레임에서 유사한 정보에서 학습하는걸로
maskTrack conv Net
이전 프레임과 다음 프레임을 컨텍팅해서 맞는 마스클를 만들어내는 방법
비디오라는 특성을 유지하면서 이전과 다음프레임의 연관성을 이용해서 뽑을수이따.

다른기법은
이전 마스크와 현재의 프레임을 두개ㅐ 넣어서  추가된것은 첫번째 프레임의 이미지와 정보를 넘겨서 마스크를 더뽑아낸다?
마스크를 propagation? 

flow propagatioon
전통적으로 옵티컬 플로우를 쓴다??? == 마스크 플로우?
아이디어를 채ㅐ용해서 input image를 넣고 optical flow image 를 전체를 처리해서 마스크를 생성하는 

mask + flow propagation
두개를 합쳐서 사용하는기법도 하고
3개를 contectiong 해서 뽑아내는 방법도 하고 

RNN (spatial++temporal)
시퀀스?? 동영상은 시퀀스 시퀀스 처리는 RNN이 좋다

mask propagation과 비슷하다. 
여러번 반복이 된다. 조금더 독특한점은 time을 시퀀스로 본것이 아니라 object를 시퀀스로 봤다. 
타임과 space를 RNN구조에 넣어서 propagation 연구도 있고

spatial temporal cnn
전부 네트워크 기능으로 치환이 ? 
인풋 이미지를 넣어주면 obtical을 뽑을거고 mask propagation필요하면 알아서 뽑을것이다.
하나의 이미지 프레임에서 마스크를 뽑고 
이미지 시퀀스를 뽑고 다음 프레임을 어떻게 할것인가 결국 flow를 예측하는 network
아래 network는 segmentation하는 네트워크이다.

DAVIS challenge
Unsupervised challenge

2018년도 우승기법
PRemVos
잘되는것을 조합해서 만들어 낸것
하나의 프레임 이미지를 보고 잘 프레임간의 관계를 이용해서 Mask RCNN ???
Deeplabv3?
전체적인 flow에서 ReID network엔지니어적 네트워크 
성능을 잘 이끌어 냈다.

issue 
instance가 너무 많은경우에 
어떤 오브젝트를 트랙킹할것인가

video saliency
이미지를 가지고 saliency를 뽑는 네트워크에 넣고 concatenation하면 saliency를 뽑게된다.

issue 2
사람이 2명이 있는경우 
다른 클래스로 적용을 해야되는데  다른오브젝트로 segmentation 하는 문제가있다. 
use motion Prior 
방법으로 해결 가능한데  
다음프레임에 그 사람이 어디에 있을지 예측하는 방법

-----

object detection 

visDrone challenge
드론으로 찍은 영상을 구별하는건데 클래스는 10개

high resolution input - tiny objects
그럼에도 불구하고 object는 굉장히작다.

coco,pascal? 
특징을 뽑는데 유리한 이미지에서 쉬운데
object 뽑느데 어려ㅕㅂ고

class imbalance 
드론에서 촬영된 영상을 분석하는게 클래스 분포가 굉장히 편차가 되어있다.
자동차,사람 이외에의 클래스 분석은 조금 어려운편이다.
클래스간의 성능편차가 매우 큰펴ㅕㄴ이다.

False positive
배를 뽑을때 차로 분석 
Densely located object
보통 object propose 한 위치가 
mms를 사용하게 되는데  오브젝트가 세밀하게 붙어있어서  mms가 옆에있는 오브젝트를 날릴수 있다..

OUr base line



Faster R-CNN
피쳐 피라미드??
네트웤에서 매우 작은 스케일을 ?

Chip based Training
오브젝트 dedection을 할때 나올수있는 작은 
전체 영상에서 어떤 특정영역을 chip으로 뽑아 정규화하고 거기있는 오브젝트만
아규먼테이셔ㅕㄴ 기법과도 비슷한데
스케일이 좀 여러개 있다는게 차이점
칩에 맞는 오브젝트만 디텍션 하는것

작은 오브젝트를 찾을부분 큰오브젝트를 찾을부분 나누는것이다.

positive/negative chip mining

negative 이미지도 만들어줘야함
오브젝트 같이 생긴걸 미리 뽑아서 chip negative chip
명시적으로 detecting하지 않게 되는것



여기서 한것
patch level augmentation

class imbalance  자전거나 차량 데이터가 없어서 아규멘테이션 해줘야한느데 그것들을
이미지를 붙여넣는것??? 붙여넣을때 스케일과 로테이션해서 성능을 높였다??
class의 밸런스를 맞춰줘야한다. 

백그라운드 이미지 학습??
다른 이미지에 영상을 붙여서 활용

hard chip mining
chip 베이스 트레이닝 하는데
?? 가지고만 하면 
positive chip이 많아진다.

patch level augmented한 이미지를 넣으면
차인데 사람으로 인식하거나 오류가 생긴다.
그런것들을 레퍼런스로 모으고 다시 칩을 만들게 된다.?
잘하는것들을 잘하게되고 못하는것 모아서 다시학습

결과로보면 네트워크 면에서 picture를 봅는데 집중한다.


----

Research Trend
video action classification

앞에서 했던 비디오 테스크 내용은 이미지에서 잘됬던것들을 가져와서 사용하고있는 수준이다.
비디오도 잘 이해하려면 video classification 몇년전부터 시도중인데
이미지에서 했던 기법들에서 크게 변화하지 않았다.

what is a video
video
sequences of 2d images
3D dimension signal with temporal coordination
T*W*H

비디오 테스크가 여러가지가 있는데
Trimmed Action Recognition
이미지set과 같다.

이게 image net보다 더큰 이미지? 데이터 셋 용량이 크다

Temporal Action Localizaition
비디오에 스트림이 있고 
어떤 장면에서 어떤 액션을 취하고있다.
어디서부터 어디까지가 어떠한 액션을 취하고있다.
temporal 공간에서 localization이다.
가장 어려우면서 궁극적으로 해결할것

spatio temporal Action localization
하나의 프레임안에서 어떤 사람이 무엇을 하고있는지 분류하는것

Trimmed action recognition이 
어떻게 접근됬는지(가장쉬운것)

2D cnn을 이용해서 액션을 분리하기
수영을 하는데 앞으로 젓는지 뒤로젓는지 영법이 달라지고
한프레임으로 알수 없다.
여러개의 프레임을 대해서 클래시피케이션 앙상블 통해서 정보얻기



그것을 퓨전하는것 어떻게 퓨전하는 방법인가

late fusion
특징을 쭉뽑고 마지막에 합성
Early fusion
미리 퓨전하고 올림

slow fusion

late fusion과 slow퓨전의 합성
2D cnn + RNN 
이미지에서 특징들을 뽑아내는것이다.
input video가 있으면
하나의 비디오 특징을 갖게되고 여러장 합쳐서 어디로 이동하고 있다. 
두개를 섞음으로서 연구가된다.

3D conv 은 
2D convoluution의 확장이다
타임축으로 하나가 증가한것 뿐이다.
네트워크의 구조는 

two stream 3D cnn 
공간의 정보를 합칠수 있기에
여러장의 이미지를 넣고 3D convnet 에서 융합해서 간다.
2년전 기법이다.
요즘에는 안함

pseudo - 3D CNNs
계산량이 매우커서 줄여나가는중인데
3 by 3by 3by 해도 27개 
디컨버제이션?? 계산량을 줄이는 방법
reduce computational complexity

계산량을 줄이기위해 처음부터 쓰는게아니라
variation을 준다.
top heavy가 bottom heavy보다 좋다.
결국 특정을 합쳐야한다. 크게 의미가 없다.
픽셀의 옵티컬 플로어가 중요하지 않다.
위쪽에서 하는것이 더 좋다. 

slowFast network
아직 연구중인 부분
face book 네트워크에서 연구중
3d를 사용하게 되는데 비디오가 처음부터 보는경우도잇고 스킵하는경우도있는데
아이디어를 가져와서 아래 네트워크는 촘촘하게 플레이
위쪽은 스킵하면서 보는것 
위쪽음 템포럴 공간상에서 무얼하고있는지
아래는 특징을 뽑는것
비디오 관련된 논문 특징 (구글,페이스북 , 테스크가 어려움,데이터의 영향이 크다)
따라잡을 방법이없음

